{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "269aa121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from hpsklearn import HyperoptEstimator\n",
    "from hpsklearn import any_classifier\n",
    "from hpsklearn import any_preprocessing\n",
    "from hyperopt import tpe\n",
    "import glob\n",
    "from hyperopt import STATUS_OK, Trials\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from hyperopt import fmin, tpe, hp\n",
    "from hpsklearn import HyperoptEstimator, any_sparse_classifier, tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75652715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(324,)\n"
     ]
    }
   ],
   "source": [
    "y=[]\n",
    "for i in range(18):\n",
    "    y= np.append(y,[i]*18)\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66e3560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "\n",
    "path0 = \"/home/nest/Downloads/poses_w1_d8/p0\"\n",
    "all_files0 = glob.glob(path0 + \"/*.csv\")\n",
    "for filename0 in all_files0:\n",
    "    df = pd.read_csv(filename0, index_col=0, header=0)\n",
    "    X.append(df)\n",
    "\n",
    "path1 = \"/home/nest/Downloads/poses_w1_d8/p1\"\n",
    "all_files1 = glob.glob(path1 + \"/*.csv\")\n",
    "for filename1 in all_files1:\n",
    "    df = pd.read_csv(filename1, index_col=0, header=0)\n",
    "    X.append(df)\n",
    "\n",
    "path2 = \"/home/nest/Downloads/poses_w1_d8/p2\"\n",
    "all_files2 = glob.glob(path2 + \"/*.csv\")\n",
    "for filename2 in all_files2:\n",
    "    df = pd.read_csv(filename2, index_col=0, header=0)\n",
    "    X.append(df)\n",
    "\n",
    "path3 = \"/home/nest/Downloads/poses_w1_d8/p3\"\n",
    "all_files3 = glob.glob(path3 + \"/*.csv\")\n",
    "for filename3 in all_files3:\n",
    "    df = pd.read_csv(filename3, index_col=0, header=0)\n",
    "    X.append(df)\n",
    "\n",
    "path4 = \"/home/nest/Downloads/poses_w1_d8/p4\"\n",
    "all_files4 = glob.glob(path4 + \"/*.csv\")\n",
    "for filename4 in all_files4:\n",
    "    df = pd.read_csv(filename4, index_col=0, header=0)\n",
    "    X.append(df)\n",
    "\n",
    "path5 = \"/home/nest/Downloads/poses_w1_d8/p5\"\n",
    "all_files5 = glob.glob(path5 + \"/*.csv\")\n",
    "for filename5 in all_files5:\n",
    "    df = pd.read_csv(filename5, index_col=0, header=0)\n",
    "    X.append(df)\n",
    "\n",
    "path6 = \"/home/nest/Downloads/poses_w1_d8/p6\"\n",
    "all_files6 = glob.glob(path6 + \"/*.csv\")\n",
    "for filename6 in all_files6:\n",
    "    df = pd.read_csv(filename6, index_col=0, header=0)\n",
    "    X.append(df)\n",
    "\n",
    "path7 = \"/home/nest/Downloads/poses_w1_d8/p7\"\n",
    "all_files7 = glob.glob(path7 + \"/*.csv\")\n",
    "for filename7 in all_files7:\n",
    "    df = pd.read_csv(filename7, index_col=0, header=0)\n",
    "    X.append(df)\n",
    "\n",
    "path8 = \"/home/nest/Downloads/poses_w1_d8/p8\"\n",
    "all_files8 = glob.glob(path8 + \"/*.csv\")\n",
    "for filename8 in all_files8:\n",
    "    df = pd.read_csv(filename8, index_col=0, header=0)\n",
    "    X.append(df)\n",
    "\n",
    "\n",
    "path9 = \"/home/nest/Downloads/poses_w1_d8/p9\"\n",
    "all_files9 = glob.glob(path9 + \"/*.csv\")\n",
    "for filename9 in all_files9:\n",
    "    df = pd.read_csv(filename9, index_col=0, header=0)\n",
    "    X.append(df)\n",
    "\n",
    "path10 = \"/home/nest/Downloads/poses_w1_d8/p10\"\n",
    "all_files10 = glob.glob(path10 + \"/*.csv\")\n",
    "for filename10 in all_files10:\n",
    "    df = pd.read_csv(filename10, index_col=0, header=0)\n",
    "    X.append(df)\n",
    "path11 = \"/home/nest/Downloads/poses_w1_d8/p11\"\n",
    "all_files11 = glob.glob(path11 + \"/*.csv\")\n",
    "for filename11 in all_files11:\n",
    "    df = pd.read_csv(filename11, index_col=0, header=0)\n",
    "    X.append(df)\n",
    "\n",
    "path12 = \"/home/nest/Downloads/poses_w1_d8/p12\"\n",
    "all_files12 = glob.glob(path12 + \"/*.csv\")\n",
    "for filename12 in all_files12:\n",
    "    df = pd.read_csv(filename12, index_col=0, header=0)\n",
    "    X.append(df)\n",
    "\n",
    "path13 = \"/home/nest/Downloads/poses_w1_d8/p13\"\n",
    "all_files13 = glob.glob(path13 + \"/*.csv\")\n",
    "for filename13 in all_files13:\n",
    "    df = pd.read_csv(filename13, index_col=0, header=0)\n",
    "    X.append(df)\n",
    "path14 = \"/home/nest/Downloads/poses_w1_d8/p14\"\n",
    "all_files14 = glob.glob(path14 + \"/*.csv\")\n",
    "for filename14 in all_files14:\n",
    "    df = pd.read_csv(filename14, index_col=0, header=0)\n",
    "    X.append(df)\n",
    "\n",
    "path15 = \"/home/nest/Downloads/poses_w1_d8/p15\"\n",
    "all_files15 = glob.glob(path15 + \"/*.csv\")\n",
    "for filename15 in all_files15:\n",
    "    df = pd.read_csv(filename15, index_col=0, header=0)\n",
    "    X.append(df)\n",
    "\n",
    "path16 = \"/home/nest/Downloads/poses_w1_d8/p16\"\n",
    "all_files16 = glob.glob(path16 + \"/*.csv\")\n",
    "for filename16 in all_files16:\n",
    "    df = pd.read_csv(filename16, index_col=0, header=0)\n",
    "    X.append(df)\n",
    "\n",
    "path17 = \"/home/nest/Downloads/poses_w1_d8/p17\"\n",
    "all_files17 = glob.glob(path17 + \"/*.csv\")\n",
    "for filename17 in all_files17:\n",
    "    df = pd.read_csv(filename17, index_col=0, header=0)\n",
    "    X.append(df)\n",
    "nsamples1, nx1, ny1 = np.shape(X)\n",
    "X_2d = np.reshape(X,(nsamples1, nx1 * ny1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc15b555",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y)\n",
    "\n",
    "nsamples, nx, ny = np.shape(X_train)\n",
    "X_train_2d = np.reshape(X_train,(nsamples, nx * ny))\n",
    "\n",
    "#print(np.shape(X_test))\n",
    "nsamples1, nx1, ny1 = np.shape(X_test)\n",
    "X_test_2d = np.reshape(X_test,(nsamples1, nx1 * ny1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a592be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a6c889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HyperoptEstimator(\n",
    "    classifier=any_classifier('cla')\n",
    "    , preprocessing=any_preprocessing('pre')\n",
    "    , algo=tpe.suggest\n",
    "    , max_evals=200\n",
    "#     , trial_timeout=30\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c038e913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function hpsklearn.components.any_classifier(name)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd8fd624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████| 1/1 [00:00<00:00,  3.45trial/s, best loss: 0.7755102040816326]\n",
      "100%|███████████| 2/2 [00:00<00:00,  5.05trial/s, best loss: 0.7551020408163265]\n",
      " 67%|████████████████████████▋            | 2/3 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:44:35] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:44:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 3/3 [00:12<00:00, 12.93s/trial, best loss: 0.30612244897959184]\n",
      "100%|██████████| 4/4 [00:00<00:00,  1.87trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████████| 5/5 [00:00<00:00,  4.35trial/s, best loss: 0.30612244897959184]\n",
      " 83%|██████████████████████████████▊      | 5/6 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:44:49] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:44:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 6/6 [00:08<00:00,  8.77s/trial, best loss: 0.30612244897959184]\n",
      "100%|██████████| 7/7 [00:00<00:00,  1.41trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████████| 8/8 [00:00<00:00,  4.11trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████████| 9/9 [00:00<00:00,  5.31trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 10/10 [00:00<00:00,  4.60trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 11/11 [00:00<00:00, 14.03trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 12/12 [00:00<00:00,  3.16trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 13/13 [00:01<00:00,  1.12s/trial, best loss: 0.30612244897959184]\n",
      "100%|████████| 14/14 [00:02<00:00,  2.76s/trial, best loss: 0.30612244897959184]\n",
      "100%|████████| 15/15 [00:00<00:00,  9.11trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 16/16 [00:01<00:00,  1.90s/trial, best loss: 0.30612244897959184]\n",
      "100%|████████| 17/17 [00:00<00:00,  9.37trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 18/18 [00:07<00:00,  7.09s/trial, best loss: 0.30612244897959184]\n",
      "100%|████████| 19/19 [00:01<00:00,  1.16s/trial, best loss: 0.30612244897959184]\n",
      "100%|████████| 20/20 [00:05<00:00,  5.73s/trial, best loss: 0.30612244897959184]\n",
      "100%|████████| 21/21 [00:00<00:00,  5.44trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 22/22 [00:00<00:00,  9.41trial/s, best loss: 0.30612244897959184]\n",
      " 96%|█████████████████████████████████▍ | 22/23 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:45:21] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:45:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|████████| 23/23 [00:00<00:00,  1.67trial/s, best loss: 0.30612244897959184]\n",
      " 96%|█████████████████████████████████▌ | 23/24 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:45:21] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:45:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|████████| 24/24 [00:05<00:00,  5.11s/trial, best loss: 0.30612244897959184]\n",
      "100%|████████| 25/25 [00:02<00:00,  2.33s/trial, best loss: 0.30612244897959184]\n",
      "100%|████████| 26/26 [00:00<00:00, 10.44trial/s, best loss: 0.30612244897959184]\n",
      " 96%|█████████████████████████████████▋ | 26/27 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:45:29] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:45:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|████████| 27/27 [00:09<00:00,  9.13s/trial, best loss: 0.30612244897959184]\n",
      "100%|████████| 28/28 [00:00<00:00,  5.98trial/s, best loss: 0.30612244897959184]\n",
      " 97%|█████████████████████████████████▊ | 28/29 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:45:38] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:45:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|████████| 29/29 [00:07<00:00,  7.15s/trial, best loss: 0.30612244897959184]\n",
      "100%|████████| 30/30 [00:00<00:00,  6.03trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 31/31 [00:00<00:00, 10.40trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 32/32 [00:00<00:00,  6.49trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 33/33 [00:00<00:00,  4.87trial/s, best loss: 0.30612244897959184]\n",
      " 97%|█████████████████████████████████▉ | 33/34 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:45:46] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:45:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|████████| 34/34 [00:06<00:00,  6.87s/trial, best loss: 0.30612244897959184]\n",
      " 97%|██████████████████████████████████ | 34/35 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████| 35/35 [40:12<00:00, 2412.31s/trial, best loss: 0.30612244897959184]\n",
      "100%|████████| 36/36 [00:00<00:00,  1.52trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 37/37 [00:00<00:00,  2.01trial/s, best loss: 0.30612244897959184]\n",
      " 97%|██████████████████████████████████ | 37/38 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:26:07] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:26:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|████████| 38/38 [00:08<00:00,  8.62s/trial, best loss: 0.30612244897959184]\n",
      "100%|████████| 39/39 [00:00<00:00,  2.00trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 40/40 [00:00<00:00,  5.80trial/s, best loss: 0.30612244897959184]\n",
      " 98%|██████████████████████████████████▏| 40/41 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:26:17] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:26:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|████████| 41/41 [00:07<00:00,  7.82s/trial, best loss: 0.30612244897959184]\n",
      "100%|████████| 42/42 [00:00<00:00, 10.26trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 43/43 [00:00<00:00,  6.70trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 44/44 [00:00<00:00,  8.07trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 45/45 [00:00<00:00,  8.48trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 46/46 [00:00<00:00,  6.25trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 47/47 [00:00<00:00,  6.60trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 48/48 [00:03<00:00,  3.92s/trial, best loss: 0.30612244897959184]\n",
      "100%|████████| 49/49 [00:00<00:00,  9.57trial/s, best loss: 0.30612244897959184]\n",
      " 98%|██████████████████████████████████▎| 49/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:26:30] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:26:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|████████| 50/50 [00:06<00:00,  6.76s/trial, best loss: 0.30612244897959184]\n",
      "100%|████████| 51/51 [00:00<00:00,  5.32trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 52/52 [00:00<00:00,  6.68trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 53/53 [00:00<00:00,  7.26trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 54/54 [00:00<00:00,  5.25trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 55/55 [00:00<00:00,  1.57trial/s, best loss: 0.30612244897959184]\n",
      " 98%|██████████████████████████████████▍| 55/56 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:26:38] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:26:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|████████| 56/56 [00:24<00:00, 24.63s/trial, best loss: 0.30612244897959184]\n",
      "100%|████████| 57/57 [00:00<00:00,  3.71trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 58/58 [00:00<00:00,  5.93trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 59/59 [00:00<00:00,  1.08trial/s, best loss: 0.30612244897959184]\n",
      " 98%|██████████████████████████████████▍| 59/60 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:27:04] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:27:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|████████| 60/60 [00:03<00:00,  3.33s/trial, best loss: 0.30612244897959184]\n",
      "100%|████████| 61/61 [00:00<00:00,  5.97trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 62/62 [00:00<00:00,  6.63trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 63/63 [00:05<00:00,  5.10s/trial, best loss: 0.30612244897959184]\n",
      "100%|████████| 64/64 [00:01<00:00,  1.11s/trial, best loss: 0.30612244897959184]\n",
      " 98%|██████████████████████████████████▍| 64/65 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:27:15] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:27:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|████████| 65/65 [00:08<00:00,  8.65s/trial, best loss: 0.30612244897959184]\n",
      "100%|████████| 66/66 [00:00<00:00,  3.18trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 67/67 [00:00<00:00,  2.91trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 68/68 [00:00<00:00,  1.05trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 69/69 [00:00<00:00,  5.27trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 70/70 [00:00<00:00,  8.06trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 71/71 [00:00<00:00,  6.93trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 72/72 [00:00<00:00,  1.25trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 73/73 [00:00<00:00,  5.76trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 74/74 [00:00<00:00,  3.70trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 75/75 [00:00<00:00,  5.39trial/s, best loss: 0.30612244897959184]\n",
      " 99%|██████████████████████████████████▌| 75/76 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:27:27] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:27:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|████████| 76/76 [00:00<00:00,  1.02trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 77/77 [00:00<00:00,  6.77trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 78/78 [00:00<00:00,  8.84trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 79/79 [00:00<00:00,  1.74trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 80/80 [00:00<00:00,  5.81trial/s, best loss: 0.30612244897959184]\n",
      " 99%|██████████████████████████████████▌| 80/81 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:27:30] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:27:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|████████| 81/81 [00:18<00:00, 18.36s/trial, best loss: 0.30612244897959184]\n",
      "100%|████████| 82/82 [00:00<00:00,  2.38trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 83/83 [00:09<00:00,  9.21s/trial, best loss: 0.30612244897959184]\n",
      "100%|████████| 84/84 [00:00<00:00,  6.08trial/s, best loss: 0.30612244897959184]\n",
      " 99%|██████████████████████████████████▌| 84/85 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:27:58] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:27:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|████████| 85/85 [00:06<00:00,  6.03s/trial, best loss: 0.30612244897959184]\n",
      "100%|████████| 86/86 [00:00<00:00,  3.53trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 87/87 [00:00<00:00,  1.47trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 88/88 [00:00<00:00,  6.63trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 89/89 [00:00<00:00,  9.59trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 90/90 [00:00<00:00,  1.54trial/s, best loss: 0.30612244897959184]\n",
      " 99%|██████████████████████████████████▌| 90/91 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:28:06] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:28:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|████████| 91/91 [00:04<00:00,  4.05s/trial, best loss: 0.30612244897959184]\n",
      "100%|████████| 92/92 [00:00<00:00,  3.33trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 93/93 [00:00<00:00,  2.20trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 94/94 [00:00<00:00, 10.18trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 95/95 [00:00<00:00,  4.60trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████| 96/96 [00:00<00:00,  5.17trial/s, best loss: 0.30612244897959184]\n",
      " 99%|██████████████████████████████████▋| 96/97 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:28:12] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:28:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|████████| 97/97 [00:02<00:00,  2.54s/trial, best loss: 0.30612244897959184]\n",
      "100%|████████| 98/98 [00:03<00:00,  3.15s/trial, best loss: 0.30612244897959184]\n",
      "100%|████████| 99/99 [00:00<00:00,  6.73trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████| 100/100 [00:02<00:00,  2.73s/trial, best loss: 0.30612244897959184]\n",
      "100%|██████| 101/101 [00:00<00:00,  6.13trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████| 102/102 [00:00<00:00,  4.91trial/s, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▋| 102/103 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:28:21] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:28:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 103/103 [00:10<00:00, 10.72s/trial, best loss: 0.30612244897959184]\n",
      "100%|██████| 104/104 [00:00<00:00,  2.36trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████| 105/105 [00:14<00:00, 14.15s/trial, best loss: 0.30612244897959184]\n",
      "100%|██████| 106/106 [00:00<00:00,  5.41trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████| 107/107 [00:00<00:00,  5.77trial/s, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▋| 107/108 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:28:47] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:28:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 108/108 [00:05<00:00,  5.74s/trial, best loss: 0.30612244897959184]\n",
      "100%|██████| 109/109 [00:00<00:00,  8.86trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████| 110/110 [00:00<00:00,  6.63trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████| 111/111 [00:00<00:00,  7.73trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████| 112/112 [00:00<00:00,  8.09trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████| 113/113 [00:00<00:00,  3.06trial/s, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▋| 113/114 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:28:54] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:28:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 114/114 [00:01<00:00,  1.24s/trial, best loss: 0.30612244897959184]\n",
      "100%|██████| 115/115 [00:01<00:00,  1.08s/trial, best loss: 0.30612244897959184]\n",
      "100%|██████| 116/116 [00:10<00:00, 10.04s/trial, best loss: 0.30612244897959184]\n",
      "100%|██████| 117/117 [00:00<00:00,  4.45trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████| 118/118 [00:00<00:00,  8.88trial/s, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▋| 118/119 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:29:07] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:29:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 119/119 [00:28<00:00, 28.96s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▋| 119/120 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:29:36] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:29:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 120/120 [00:29<00:00, 29.35s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▋| 120/121 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:30:05] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:30:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 121/121 [00:21<00:00, 21.12s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▋| 121/122 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:30:27] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:30:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 122/122 [00:14<00:00, 14.21s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▋| 122/123 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:30:41] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:30:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 123/123 [00:06<00:00,  6.67s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▋| 123/124 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:30:48] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:30:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 124/124 [00:07<00:00,  7.72s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▋| 124/125 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:30:55] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:30:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 125/125 [00:25<00:00, 25.82s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▋| 125/126 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:31:21] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:31:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 126/126 [00:27<00:00, 27.79s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▋| 126/127 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:31:49] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:31:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 127/127 [00:23<00:00, 23.54s/trial, best loss: 0.30612244897959184]\n",
      "100%|██████| 128/128 [00:00<00:00,  6.19trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████| 129/129 [00:00<00:00,  4.11trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████| 130/130 [00:00<00:00,  4.72trial/s, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▋| 130/131 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:14] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 131/131 [00:16<00:00, 16.32s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 131/132 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:30] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 132/132 [00:17<00:00, 17.58s/trial, best loss: 0.30612244897959184]\n",
      "100%|██████| 133/133 [00:00<00:00,  3.01trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████| 134/134 [00:00<00:00,  4.64trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████| 135/135 [00:00<00:00,  2.33trial/s, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 135/136 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:49] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 136/136 [00:26<00:00, 26.61s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 136/137 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:16] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 137/137 [00:18<00:00, 18.47s/trial, best loss: 0.30612244897959184]\n",
      "100%|██████| 138/138 [00:00<00:00,  8.44trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████| 139/139 [00:00<00:00,  1.03trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████| 140/140 [00:00<00:00,  1.90trial/s, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 140/141 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:36] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 141/141 [00:34<00:00, 34.93s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 141/142 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:11] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 142/142 [00:26<00:00, 26.73s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 142/143 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:38] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 143/143 [00:14<00:00, 14.64s/trial, best loss: 0.30612244897959184]\n",
      "100%|██████| 144/144 [00:00<00:00,  1.10trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████| 145/145 [00:00<00:00,  7.34trial/s, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 145/146 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:54] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 146/146 [00:35<00:00, 35.17s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 146/147 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:29] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 147/147 [00:35<00:00, 35.09s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 147/148 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:36:04] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:36:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 148/148 [00:06<00:00,  6.56s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 148/149 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:36:11] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:36:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 149/149 [00:22<00:00, 22.71s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 149/150 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:36:33] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:36:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 150/150 [00:26<00:00, 26.12s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 150/151 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:37:00] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:37:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 151/151 [00:24<00:00, 24.95s/trial, best loss: 0.30612244897959184]\n",
      "100%|██████| 152/152 [00:00<00:00,  3.54trial/s, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 152/153 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:37:25] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:37:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 153/153 [00:17<00:00, 17.97s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 153/154 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:37:43] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:37:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 154/154 [00:22<00:00, 22.71s/trial, best loss: 0.30612244897959184]\n",
      "100%|██████| 155/155 [00:00<00:00,  6.68trial/s, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 155/156 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:38:06] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:38:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 156/156 [00:21<00:00, 21.66s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 156/157 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:38:28] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:38:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 157/157 [00:38<00:00, 38.68s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 157/158 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:39:06] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:39:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 158/158 [00:26<00:00, 26.68s/trial, best loss: 0.30612244897959184]\n",
      "100%|██████| 159/159 [00:00<00:00,  4.44trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████| 160/160 [00:00<00:00,  3.35trial/s, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 160/161 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:39:34] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:39:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 161/161 [00:25<00:00, 25.83s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 161/162 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:40:00] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:40:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 162/162 [00:06<00:00,  6.57s/trial, best loss: 0.30612244897959184]\n",
      "100%|██████| 163/163 [00:00<00:00,  8.58trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████| 164/164 [00:00<00:00,  2.76trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████| 165/165 [00:00<00:00,  5.39trial/s, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 165/166 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:40:07] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:40:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 166/166 [00:06<00:00,  6.70s/trial, best loss: 0.30612244897959184]\n",
      "100%|██████| 167/167 [00:00<00:00,  3.41trial/s, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 167/168 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:40:14] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:40:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 168/168 [00:02<00:00,  2.60s/trial, best loss: 0.30612244897959184]\n",
      "100%|██████| 169/169 [00:00<00:00,  2.01trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████| 170/170 [00:00<00:00,  8.68trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████| 171/171 [00:00<00:00,  4.76trial/s, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 171/172 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:40:18] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:40:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 172/172 [00:03<00:00,  3.60s/trial, best loss: 0.30612244897959184]\n",
      "100%|██████| 173/173 [00:00<00:00,  8.09trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████| 174/174 [00:00<00:00,  1.41trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████| 175/175 [00:00<00:00,  5.81trial/s, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 175/176 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:40:23] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:40:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 176/176 [00:01<00:00,  1.91s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 176/177 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:40:25] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:40:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 177/177 [00:12<00:00, 12.21s/trial, best loss: 0.30612244897959184]\n",
      "100%|██████| 178/178 [00:19<00:00, 19.51s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 178/179 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:40:57] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:40:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 179/179 [00:10<00:00, 10.08s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 179/180 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:41:07] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:41:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 180/180 [00:14<00:00, 14.31s/trial, best loss: 0.30612244897959184]\n",
      "100%|██████| 181/181 [00:00<00:00,  5.78trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████| 182/182 [00:00<00:00,  4.55trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████| 183/183 [00:00<00:00,  8.54trial/s, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 183/184 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:41:22] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:41:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 184/184 [00:23<00:00, 23.00s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 184/185 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:41:45] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:41:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 185/185 [00:24<00:00, 24.96s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 185/186 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:42:10] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:42:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 186/186 [00:20<00:00, 20.61s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 186/187 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:42:31] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:42:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 187/187 [00:27<00:00, 27.68s/trial, best loss: 0.30612244897959184]\n",
      "100%|██████| 188/188 [00:01<00:00,  1.55s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 188/189 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:43:00] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:43:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 189/189 [00:12<00:00, 12.76s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 189/190 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:43:13] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:43:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 190/190 [00:03<00:00,  3.09s/trial, best loss: 0.30612244897959184]\n",
      "100%|██████| 191/191 [00:01<00:00,  1.31s/trial, best loss: 0.30612244897959184]\n",
      "100%|██████| 192/192 [00:01<00:00,  1.43s/trial, best loss: 0.30612244897959184]\n",
      "100%|██████| 193/193 [00:00<00:00,  3.15trial/s, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 193/194 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:43:19] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:43:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 194/194 [00:05<00:00,  5.76s/trial, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 194/195 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:43:25] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:43:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 195/195 [00:12<00:00, 12.85s/trial, best loss: 0.30612244897959184]\n",
      "100%|██████| 196/196 [00:00<00:00,  7.30trial/s, best loss: 0.30612244897959184]\n",
      " 99%|████████████████████████████████▊| 196/197 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:43:38] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:43:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 197/197 [00:09<00:00,  9.60s/trial, best loss: 0.30612244897959184]\n",
      "100%|██████| 198/198 [00:00<00:00,  6.65trial/s, best loss: 0.30612244897959184]\n",
      "100%|██████| 199/199 [00:00<00:00,  7.57trial/s, best loss: 0.30612244897959184]\n",
      "100%|████████████████████████████████▊| 199/200 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:43:48] WARNING: ../src/learner.cc:576:                                      \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:43:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████| 200/200 [00:14<00:00, 14.72s/trial, best loss: 0.30612244897959184]\n",
      "[09:44:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:44:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nest/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_2d, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f210610b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.667\n"
     ]
    }
   ],
   "source": [
    "# summarize performance\n",
    "acc = model.score(X_test_2d, y_test)\n",
    "print(\"Accuracy: %.3f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd0bdc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.667\n",
      "{'learner': XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "              colsample_bylevel=0.8829916694189455, colsample_bynode=1,\n",
      "              colsample_bytree=0.7921481346785287, enable_categorical=False,\n",
      "              gamma=0.07224330366768723, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.007632392370878855,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=2400, n_jobs=1,\n",
      "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
      "              random_state=0, reg_alpha=0.002852545448673046,\n",
      "              reg_lambda=3.69116846136906, scale_pos_weight=1, seed=0,\n",
      "              subsample=0.6932100898765085, tree_method='exact',\n",
      "              validate_parameters=1, verbosity=None), 'preprocs': (StandardScaler(),), 'ex_preprocs': ()}\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %.3f\" % acc)\n",
    "print(model.best_model())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfdda0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
